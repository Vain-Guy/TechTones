{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb00217",
   "metadata": {},
   "source": [
    "# BUSINESS UNDERSTANDING\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "This is a Natural Language Processing (NLP)-driven sentiment analysis project designed to decode public opinion on two of the world’s most influential tech companies; **Apple** and **Google**. By leveraging machine learning techniques to analyze thousands of real tweets, the project aims to classify user sentiment as *positive*, *negative*, or *neutral*.  \n",
    "\n",
    "This initiative demonstrates how social media analytics can provide actionable insights for companies seeking to understand consumer perceptions, monitor brand reputation, and anticipate market trends. Ultimately, the project serves as a prototype for a scalable, intelligent sentiment monitoring system applicable across industries.\n",
    "\n",
    "## BACKGROUND\n",
    "\n",
    "Social media has become the world’s largest real-time feedback loop. Millions of users share their thoughts daily about products, services, and brands—creating a goldmine of unstructured data that reveals how people truly feel.  \n",
    "For technology companies like **Apple** and **Google**, such sentiment can directly influence *brand equity*, *purchase behavior*, and *public trust*. Tweets praising a product’s innovation or criticizing a software update can ripple across digital spaces, shaping collective opinion within hours.  \n",
    "Understanding these emotional currents is therefore critical for modern businesses. Sentiment analysis transforms raw textual chatter into measurable, strategic insight—empowering companies to react faster, market smarter, and communicate better.\n",
    "\n",
    "## OBJECTIVES\n",
    "\n",
    "The main goals of the project are to:\n",
    "\n",
    "1. Develop a Natural Language Processing (NLP) model that classifies tweets related to Apple and Google as *positive*, *negative*, or *neutral*.  \n",
    "2. Preprocess and transform raw text into machine-readable features using tokenization, normalization, stopword removal, and TF-IDF vectorization.  \n",
    "3. Evaluate multiple machine learning algorithms to identify the most accurate and interpretable classifier.  \n",
    "4. Generate data-driven insights about brand sentiment patterns to support business and marketing decisions.  \n",
    "5. Lay the groundwork for an automated brand intelligence system capable of tracking sentiment across multiple platforms and industries.\n",
    "\n",
    "## SUCCESS METRICS\n",
    "\n",
    "Success will be defined through a mix of technical and business outcomes:\n",
    "\n",
    "- **Model Performance:** Achieving at least 80% F1-score across sentiment classes.  \n",
    "- **Data Integrity:** Clean, balanced, and reproducible dataset suitable for future extensions.  \n",
    "- **Interpretability:** Ability to visualize top sentiment-driving words and phrases for explainability.  \n",
    "- **Insight Quality:** Sentiment trends that clearly reflect real-world brand perceptions.  \n",
    "- **Scalability:** Modular design allowing future integration with streaming APIs for live monitoring.\n",
    "\n",
    "## STAKEHOLDERS\n",
    "\n",
    "The beneficiaries of this undertaking include:\n",
    "  \n",
    "- **Marketing Analysts:** Use sentiment insights to understand public opinion and campaign impact.  \n",
    "- **Product Managers:** Monitor consumer feedback and sentiment shifts after product launches.  \n",
    "- **Executives & Decision Makers:** Leverage findings to inform strategic brand and communication strategies.\n",
    "- **Data Science & NLP Teams:** Responsible for model design, feature engineering, and evaluation.  \n",
    "- **Research & Development Teams:** Explore applications of the model in broader domains like product reviews, customer feedback, and crisis management.\n",
    "\n",
    "### RELEVANCE\n",
    "\n",
    "TechTones bridges the gap between data and perception. It shows how machine learning can turn the chaos of social media into structured intelligence; helping organizations not only track how people feel, but also why they feel that way.\n",
    "This project highlights the growing role of NLP in business strategy, reputation management, and competitive intelligence, providing a strong proof of concept for sentiment analysis as a key driver of modern data-driven decision-making.\n",
    "\n",
    "# DATA UNDERSTANDING\n",
    " \n",
    "The dataset used in this project is sourced from [CrowdFlower](https://data.world/crowdflower/brands-and-product-emotions) and contains over 9,000 Tweets referencing Apple and Google products. Each Tweet has been annotated with information identifying the product or brand mentioned and the emotion expressed toward it. It offers a real-world foundation for supervised sentiment analysis in Natural Language Processing (NLP). \n",
    "\n",
    "It contains the following features with their descriptions:\n",
    "\n",
    "| Feature | Description |\n",
    "|--------------|----------------|\n",
    "| tweet_text | The full text of each Tweet referencing Apple or Google products. |\n",
    "| emotion_in_tweet_is_directed_at | The product or brand mentioned (e.g iPhone, iPad, Google, iPad/iPhone App). |\n",
    "| is_there_an_emotion_directed_at_a_brand_or_product | The annotated sentiment label -> *Positive emotion*, *Negative emotion*, or *No emotion toward brand or product*. |\n",
    "\n",
    "This schema supports a supervised learning setup where tweet_text acts as the input feature and is_there_an_emotion_directed_at_a_brand_or_product serves as the target variable for classification.\n",
    "\n",
    "Awesome! Now, let's get our hands dirty.\n",
    "\n",
    "### EXPLORING THE DATA\n",
    "\n",
    "We begin by loading the data and performing an initial exploration to get a sense of its structure and content. But first, we gather our essential tools; just as a painter readies their palette and brushes before creating a masterpiece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e14c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ======= [Import all relevant libraries] =======\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Usual Suspects\n",
    "import numpy as np           # Mathematical operations\n",
    "import pandas as pd          # Data manipulation\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "import seaborn as sns\n",
    "\n",
    "# String manipulation\n",
    "import re\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize                     # Tokenization\n",
    "from nltk.corpus import stopwords                           # Stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer      # Stemming & Lemmatization\n",
    "\n",
    "# Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ML Models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression         # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier             # Decision Tree\n",
    "\n",
    "# ML Model Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    ConfusionMatrixDisplay, confusion_matrix,\n",
    "    roc_curve, auc,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Set column display to maximum\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77ba25",
   "metadata": {},
   "source": [
    "Now we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7565113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9088                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9089                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9090  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9091       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9092                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\lenovo\\\\OneDrive\\\\Desktop\\\\DS\\\\PROJECTS\\\\TechTones\\\\Apple and Google Twitter Sentiments.csv\", encoding=\"ISO-8859-1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2404f8c",
   "metadata": {},
   "source": [
    "*Observation:* The dataset is consistent and admittedly very messy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea474939",
   "metadata": {},
   "source": [
    "Then we check the number of records and fatures we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc7af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 9093 records and 3 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset has {df.shape[0]} records and {df.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cdfa5",
   "metadata": {},
   "source": [
    "We’ve got over 9,000 records, a solid data haul. Let’s see how unique the dataset is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73e29953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in: \n",
      "\n",
      "tweet_text: 9065 unique values\n",
      "emotion_in_tweet_is_directed_at: 9 unique values\n",
      "is_there_an_emotion_directed_at_a_brand_or_product: 4 unique values\n",
      "\n",
      "Unique Values in:\n",
      "\n",
      "tweet_text:\n",
      "['.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.'\n",
      " \"@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\"\n",
      " '@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.'\n",
      " ...\n",
      " \"Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev\"\n",
      " 'Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.'\n",
      " '\\x8cÏ¡\\x8eÏà\\x8aü_\\x8b\\x81Ê\\x8b\\x81Î\\x8b\\x81Ò\\x8b\\x81£\\x8b\\x81Á\\x8bââ\\x8b\\x81_\\x8b\\x81£\\x8b\\x81\\x8f\\x8bâ_\\x8bÛâRT @mention Google Tests \\x89ÛÏCheck-in Offers\\x89Û\\x9d At #SXSW {link}']\n",
      "\n",
      "emotion_in_tweet_is_directed_at:\n",
      "['iPhone' 'iPad or iPhone App' 'iPad' 'Google' nan 'Android' 'Apple'\n",
      " 'Android App' 'Other Google product or service'\n",
      " 'Other Apple product or service']\n",
      "\n",
      "is_there_an_emotion_directed_at_a_brand_or_product:\n",
      "['Negative emotion' 'Positive emotion'\n",
      " 'No emotion toward brand or product' \"I can't tell\"]\n"
     ]
    }
   ],
   "source": [
    "# ======= [Dataset Uniqueness] =======\n",
    "\n",
    "# Number of unique values in each column\n",
    "print(\"Number of unique values in:\", '\\n')\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# Unique values in each column\n",
    "print(\"\\nUnique Values in:\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfbf1c9",
   "metadata": {},
   "source": [
    "*Observation:*\n",
    "\n",
    "- There are over 9,065 unique tweet entries, meaning nearly every tweet in the dataset is distinct.\n",
    "- These tweets are directed to 9 unique products, capturing a range of Apple and Google products (like iPhone, Android, iPad) and some general or unspecified mentions. The presence of NaN values suggests that some tweets don’t explicitly mention a product.\n",
    "- There are 4 distinct emotional classifications, reflecting the sentiment intensity or clarity.\n",
    "\n",
    "Based on this initial preview, it makes sense to standardize the column names; keeping them short, clear, and easy to work with during analysis and manipulation. We’ll rename them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f97f0b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'product', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "df.rename(columns={\n",
    "    'tweet_text': 'tweet',\n",
    "    'emotion_in_tweet_is_directed_at': 'product',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'\n",
    "}, inplace=True)\n",
    "\n",
    "# Preview new column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236cfd6",
   "metadata": {},
   "source": [
    "We further check the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53411486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      9092 non-null   object\n",
      " 1   product    3291 non-null   object\n",
      " 2   sentiment  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bedb6d",
   "metadata": {},
   "source": [
    "*Interpretation:*\n",
    "\n",
    "- All fields are categorical which is consistent with the data as it is in text format.\n",
    "- tweet: Almost complete, with 9,092 non-null values, meaning only one missing entry.\n",
    "- product: Has 3,291 non-null values, showing that about 36% of tweets mention a specific Apple or Google product. The rest are either general statements or lack a clear product reference.\n",
    "- sentiment: Fully populated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1177d4b",
   "metadata": {},
   "source": [
    "Next, we aim to deepen our understanding of the dataset by exploring the descriptive statistics of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6268eb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>9092</td>\n",
       "      <td>9065</td>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect the Digital &amp;amp; Physical Worlds Through Mobile - {link} #sxsw</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>3291</td>\n",
       "      <td>9</td>\n",
       "      <td>iPad</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>9093</td>\n",
       "      <td>4</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>5389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique  \\\n",
       "tweet      9092   9065   \n",
       "product    3291      9   \n",
       "sentiment  9093      4   \n",
       "\n",
       "                                                                                                                      top  \\\n",
       "tweet      RT @mention Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxsw   \n",
       "product                                                                                                              iPad   \n",
       "sentiment                                                                              No emotion toward brand or product   \n",
       "\n",
       "           freq  \n",
       "tweet         5  \n",
       "product     946  \n",
       "sentiment  5389  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbee4cd",
   "metadata": {},
   "source": [
    "*Observation:*\n",
    "\n",
    "We observe that:\n",
    "\n",
    "- The most repeated tweet appears only 5 times, suggesting very little duplication.\n",
    "- Products (product): Out of all the 9 distinct products, iPads lead the conversation -> mentioned 946 times, indicating a strong public interest in them.\n",
    "- The dataset is dominated by neutral or indifferent opinions -> 'No emotion toward brand or product' appears 5,389 times, making up more than half the data. This suggests that while people talk about these brands a lot, many tweets don’t clearly express positive or negative emotions -> neutrality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87f5c5",
   "metadata": {},
   "source": [
    "### DATA QUALITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37732fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate: 22\n",
      "\n",
      "Missing values and percentage missingness:\n",
      "            Missing Values  Percentage\n",
      "tweet                   1    0.010997\n",
      "product              5802   63.807324\n",
      "sentiment               0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# ======= [Check for duplicates and missing values] =======\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "\n",
    "# Check for missing values and missingness percentage\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "print(\"\\nMissing values and percentage missingness:\\n\", missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435acda",
   "metadata": {},
   "source": [
    "*Observation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6f851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
